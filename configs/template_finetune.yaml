dataset:
    # Format 1
    file_path:
        train: str
        test: str
    # Format 2
    file_path: str
    test_split: float [>0.0, <1.0]
    # other kwargs
    code_field: str
    label_field: str
    type_field: <optional> str
transformer:
    model_name_or_path: str                 # base model
    config_name: <optional> str
    tokenizer_name: <optional> str
    do_lower_case: <optional> [True, False]
    quantization_bits: <optional> [4, 8]
    add_special_tokens: <optional> [True, False]
    custom_tokens: <optional> list
peft:
    type: str
    task: str
    kwargs...: ...
    # If `task` == 'lora', then
    long_lora: <optional> [True, False]     # override `modules_to_save`
    all_linear: <optional> [True, False]
runner:
    train_batch_size: int                   # NECESSARY, override `per_devive_train_batch_size`
    eval_batch_size: int                    # NECESSARY, override `per_devive_eval_batch_size`
    max_seq_length: <optional> int
    kwargs...: ...
seed: <optional> int